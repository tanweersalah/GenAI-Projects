{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cassio in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.1.8)\n",
      "Requirement already satisfied: datasets in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.20.0)\n",
      "Requirement already satisfied: langchain in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.2.10)\n",
      "Requirement already satisfied: openai in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.36.0)\n",
      "Requirement already satisfied: tiktoken in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.7.0)\n",
      "Collecting PyPDF2 (from -r requirements.txt (line 6))\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: cassandra-driver<4.0.0,>=3.28.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from cassio->-r requirements.txt (line 1)) (3.29.1)\n",
      "Requirement already satisfied: numpy>=1.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from cassio->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from cassio->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: filelock in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: packaging in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 3)) (2.0.31)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.22 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 3)) (0.2.22)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 3)) (0.1.93)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 3)) (1.10.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 3)) (8.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 5)) (2024.5.15)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 4)) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from cassandra-driver<4.0.0,>=3.28.0->cassio->-r requirements.txt (line 1)) (0.2.1.post1)\n",
      "Requirement already satisfied: certifi in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.22->langchain->-r requirements.txt (line 3)) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 3)) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->cassio->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->cassio->-r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: click in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: six in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/tanweersalah/anaconda3/envs/langchain/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain->-r requirements.txt (line 3)) (3.0.0)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r 'requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader('cv.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 30 0 (offset 0)\n",
      "Ignoring wrong pointing object 33 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 57 0 (offset 0)\n",
      "Ignoring wrong pointing object 63 0 (offset 0)\n",
      "Ignoring wrong pointing object 66 0 (offset 0)\n",
      "Ignoring wrong pointing object 71 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "pdf_doc = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=\"\\n\",chunk_size = 300, chunk_overlap = 100)\n",
    "documents = text_splitter.split_documents(pdf_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'cv.pdf', 'page': 0}, page_content=\"Mohammad Tanweer Salah     tanweer.salah@gmail.com | +49 17646675017  Berlin, Germany LinkedIn | GitHub  SUMMARY  Full Stack Developer with Expertise in Python, Java, .NET Core, and Generative AI   With over 5 years of practical experience and 3.5 years of professional expertise, I specialize in developing scalable web applications using Java and .NET Core. My recent projects include multiple innovative applications of Generative AI, leveraging LangChain and open-source Large Language Models (LLMs) to address diverse use cases.    SKILLS  Generative AI: Open Source LLMs, OpenAI LLM, LangChain, LangChain Agents, LangChain Tool, LLamaIndex, RAG, Vector Database, GraphDB Machine Learning: TensorFlow, TensorFlow Lite Back-End: Python, FastAPI, Java Spring Boot, .Net Core, C#, Java, Rest API, JSON Front-End: JavaScript, Typescript, Vue.js, React.js, Streamlit, HTML5, CSS3, Adobe XD, Figma Database: GraphDB, PostgreSQL , SQL, Azure Storage Services Tools & Methods: Azure, Docker, Git, GitHub, Azure DevOps, CI/CD,  OS: Linux, Mac, Windows Professional: Jira, Confluence, Remote Pair-Programming, Teamwork Soft Skills : Collaboration, Productivity, Creativity, Continuous Learning, Problem Solving, Agile Methodology, Documentation, Communication skills  PROJECTS TanGPT - Demo ‚Ä¢ A ChatGPT clone built using open-source large language models, LangChain, FastAPI, and Vue.js. The project is deployed with Docker and uses Nginx for proxy management. YouTube Video and Webpage Summarizer - Demo ‚Ä¢ A generative AI application that utilizes open-source large language models to summarize lengthy videos and web pages using the MapReduce method. The application is deployed on Streamlit. TanSeo (SEO optimizer App) - Demo ‚Ä¢ A content generation project that produces SEO-optimized web page content using open-source large language models and a series of SEO-specific prompts. Translator App- Demo ‚Ä¢ A translation application capable of translating multiple languages, built with open-source large language models. Movie review sentiment analysis App- Demo ‚Ä¢ A sentiment analysis application that uses three different models (ANN, RNN, and LSTM) trained on IMDB datasets to analyse movie reviews. TanFlix  ‚Ä¢ A Netflix clone with movie recommendation system, trained on The Movie Database (TMDB) Facial Expressions Detection ‚Ä¢ Facial Expression Recognition using YOLOv5 and RepVGG (CNN)  ‚Ä¢ ‚Ä¢ Skills: Python, TensorFlow, NumPy, OpenCV (CV2), Pandas, Seaborn, TensorFlow Developed an IoT-based Vehicle Accident Detector ‚Ä¢ Implemented shock and gyro sensors to accurately detect accidents, ensuring real-time monitoring and response. ‚Ä¢ Emergency Notification System: Designed and integrated an Android app to send immediate emergency notifications to the driver's contacts, enhancing safety and response times. Pneumonia type detection from X-Ray scans using Deep CNNs ‚Ä¢ CNN was used for classifying Viral pneumonia into COVID/MERS/SARS. ‚Ä¢ ResNet50 architecture was implemented to classify Bacterial pneumonia from normal chest X-Ray scans and achieved 94% training accuracy & 94% validation accuracy. \"),\n",
       " Document(metadata={'source': 'cv.pdf', 'page': 1}, page_content=' EXPERIENCE  Fraunhofer IPK Berlin, Germany (On-site) Research Assistant 10/2023 ‚Äì present Project - Catena X  An open data ecosystem for the automotive industry designed to create data chains.  ‚Ä¢ Developing an application called CE (Circular Economy) Assistant. Targeting use case: Circular economy, specifically addressing End-of-Life (EoL) of vehicles. ‚Ä¢ Handling complete end-to-end development: o Frontend development using Vue.js o Backend development utilizing Java Spring Boot. o DevOps processes including CI/CD pipeline setup, cloud deployment, and monitoring ‚Ä¢ Building comprehensive data models for different use cases to ensure accurate and efficient data handling.  Tata Consultancy Services Delhi, India (On-site) System Engineer 11/2020 ‚Äì 03/2023 Project - POS for Visionworks of America  A Optical retail chain with more than 700 stores across United States of America.  ‚óè Developed POS and CRM systems, enhancing workflow. ‚óè Developed multiple Azure Function Apps and leveraging serverless computing. ‚óè Designed and developed secure Web APIs and Set up CI/CD pipelines with Azure DevOps. ‚óè Created multiple internal automation tools for increasing efficiency and saving 60 hours / week of manual work.  ‚óè Implemented data migration, saving $300K annually.  ‚óè Nominated for the Best Performance Improvement Award.  EDUCATION  MSc, Artificial Intelligence  10/2023 ‚Äì Present Universit√§t zu L√ºbeck, Germany    Bachelor of Engineering,  Automobile Engineering  09/2016 ‚Äì 08/2020 Rajiv Gandhi Proudyogiki Vishwavidyalaya, India   CERTIFICATIONS  ‚Ä¢ TensorFlow Developer Professional Certification (06/2023) - '),\n",
       " Document(metadata={'source': 'cv.pdf', 'page': 1}, page_content='üîó ‚Ä¢ Machine learning Specialisation (05/2023) - \\nüîó ‚Ä¢ Artificial Intelligence Fundamentals AI - 900 - Microsoft Certification (06/2021) - \\nüîó ‚Ä¢ Infosys Certified Software Programmer (07/2019) - \\nüîó ‚Ä¢ Programming in Java - Certification (05/2019) - \\nüîó ‚Ä¢ Python Developer Certification -'),\n",
       " Document(metadata={'source': 'cv.pdf', 'page': 1}, page_content='üîó ‚Ä¢ Programming in Java - Certification (05/2019) - \\nüîó ‚Ä¢ Python Developer Certification - \\nüîó ‚Ä¢ Azure Fundamentals AZ - 900 - Microsoft Certification (06/2021) - \\nüîó ‚Ä¢ Data Fundamentals DP - 900 - Microsoft Certification (06/2021) - \\nüîó ‚Ä¢ IELTS BAND - 7 | CEFR LEVEL - C1 (03/2022) \\nüîó')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "import cassio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 10\n",
      "Python-dotenv could not parse statement starting at line 11\n",
      "Python-dotenv could not parse statement starting at line 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(token=os.getenv('ASTRA_DB_APPLICATION_TOKEN'), database_id= os.getenv('ASTRA_DB_ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store = Cassandra(embedding=embedding,\n",
    "                               table_name='cv_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['506286a676e14ab783c4f2b7aa4bd5f4',\n",
       " '03db0dfcf16b458a92133e81aaac66d1',\n",
       " '3676287270374e65a50df3712efe5877',\n",
       " '372b90f2349a412c86babeb763c0605e']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astra_vector_store.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The email is tanweer.salah@gmail.com.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astra_vector_index.query('what is the email ?', llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the skills related to Generative AI are:\\n\\n* Open Source LLMs (Large Language Models)\\n* OpenAI LLM\\n* LangChain\\n* LangChain Agents\\n* LangChain Tool\\n* LLamaIndex\\n* RAG (Reasoning-Augmented Generation)\\n* Vector Database\\n* GraphDB'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astra_vector_index.query('what are skill related to gen ai', llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided context, Mohammad Tanweer Salah has a strong background in Generative AI, Machine Learning, and Software Development, which makes him a good fit for an internship position in Gen AI.\\n\\nHere are some points that support his qualification:\\n\\n1. **Certifications**: He has certifications in Artificial Intelligence Fundamentals, TensorFlow Developer Professional Certification, and Python Developer Certification, which demonstrate his knowledge and skills in AI and ML.\\n2. **Projects**: He has worked on several projects that involve Generative AI, such as TanGPT (a ChatGPT clone), YouTube Video and Webpage Summarizer, TanSeo (SEO optimizer App), and Translator App, which showcase his hands-on experience with Gen AI.\\n3. **Skills**: His skills include Open Source LLMs, LangChain, LangChain Agents, LangChain Tool, LLamaIndex, RAG, Vector Database, and GraphDB, which are all relevant to Gen AI.\\n4. **Education**: He is currently pursuing a Master's degree in Artificial Intelligence, which further strengthens his background in AI and ML.\\n\\nOverall, based on his certifications, projects, skills, and education, Mohammad Tanweer Salah appears to be a strong candidate for an internship position in Gen AI.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astra_vector_index.query('is he qualified for intership position for Gen AI', llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
